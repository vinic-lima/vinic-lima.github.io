[
  {
    "objectID": "rstata.html",
    "href": "rstata.html",
    "title": "Coding in R, Python and Stata",
    "section": "",
    "text": "It’s likely that you won’t find any brand new content here compared to what you can find making some research on the web.\nHowever, I built this page to serve as a kind of personal library gathering a lot of stuff I did in both R and Stata.\nThe content is organized into the categories that see in the right bar.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultiple estimation with custom statistics\n\n\n\n\n\n\n\n\n\n\n\n\nVinicius Lima\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Vinicius Lima",
    "section": "",
    "text": "Hi!\nI’m a post-doctoral researcher at Insper in São Paulo, Brazil.\nI have a broad interest in topics of development economics covering education, labor, crime and political economy.\nHere you can find information about my research, teaching experience, and some personal information.\nCV."
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "Group size, member selection, and performance: Evidence from legislative elections in Brazil\n(Submitted)\n\n\nAbstract [Manuscript]\n\n\nThis paper provides empirical evidence on the causal effects of group size on member selection and performance. Using data from local legislative elections in Brazil in a difference-in-differences framework, I explore an electoral reform that reduced the maximum number of candidates allowed in coalitions disputing legislative seats. The reform did not change the number of candidates and parties in the election, which was possible because in municipalities affected by the new cap parties reorganized into 21% more coalitions than would be expected without the reform. I discuss how the heterogeneity of the candidates combined with the characteristics of the coalitions’ production functions led to the recruitment of candidates who were 13% wealthier and the election of city councilors who were 17% wealthier, on average. The reform achieved the goal of reducing campaign costs, which fell by 9%. However, the election of wealthier politicians is an unintended consequence that is in the opposite direction of reducing the power of money in politics.\n\n\nPeer Effects in Active Learning (with Vladimir Ponczek and Priscilla Tavares)\n(Submitted)\n\n\nAbstract [Manuscript]\n\n\nThis paper studies peer effects in an active learning environment, where peer interaction is a meaningful learning mechanism. Identification of peer effects relies on the random assignment of students to different disciplines in a higher education institution. We leverage random variation in the peers’ ability distribution across groups and in the frequency at which peers meet for group work and show that social proximity among peers is increasing in the number of groups the students share and in how close they are in terms of their predetermined ability. Our main results show that replacing a socially distant peer with a closer one increases the average score of low-ability students in written exams by 2.8%. Also, the probability that low-ability students receive an evaluation corresponding to outstanding performance in group work increases by 30%, which demonstrates that social proximity makes them exert more effort. There are no detectable effects on the high-ability students’ grades. This highlights the importance of peer interaction in positive peer effects on the academic performance of low-skilled individuals.\n\n\nDomestic Violence Law Enforcement and Women’s Labor Market Participation\n\n\nAbstract [Manuscript]\n\n\nThis paper uses Brazilian data to investigate the effects of a law aimed at tackling domestic violence on women’s labor market participation in a difference-in-differences framework. The law increased the probability of punishment of DV perpetrators, and the paper’s main hypothesis is that it improved women’s negotiating position within households, leading to a redistribution of bargaining power in favor of them. The identification strategy leverages spatial heterogeneity in the access to police stations, the first step into the justice system. The paper’s main finding shows that after the policy, married women living at an average distance of 2.7 km from a police station (the 90th percentile) would have experienced a 2.9% increase in their labor market participation rate had they lived at an average of 1.1 km (the 10th percentile). I show supporting evidence of reduced women’s hospitalization due to violence and that reporting of crimes related to domestic violence responded consistently. These findings shed light on the interplay between law enforcement, household dynamics, and labor market outcomes."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Vinicius Lima",
    "section": "",
    "text": "PhD in Economics, 2017 - 2021\nM.A. in Economics, 2015 - 2017\n\n\n\nB.A in Economics, Sept 2009 - 2013"
  },
  {
    "objectID": "research.html#work-in-progress",
    "href": "research.html#work-in-progress",
    "title": "Research",
    "section": "Work in Progress",
    "text": "Work in Progress\nTit-for-Tat between Legislative and Executive (with Eduardo Ferraz and Lucas Finamor)\nCorruption Disclosure and the Dynamics of Government Coalitions\nThe Impact of Alternative Dispute Resolution Mechanisms on Violence Against Women (with Giovanna Úbida)"
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "Principles of Microeconomics, Microeconomic Theory, Industrial Organization\nMathematics I and II, Linear Algebra\nProbability, Statistics, Econometrics I (cross-section)\n\n\n\n\n\nTeaching assistant in Statistics and Econometrics\n\n\n\n\n\nTeaching assitant in Microeconomic Theory, Econometrics I and III (cross-section and Panel Data)"
  },
  {
    "objectID": "posts/01_multiple_estim_custom_stats.html",
    "href": "posts/01_multiple_estim_custom_stats.html",
    "title": "Multiple estimation with custom statistics",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "posts/01_multiple_estim_custom_stats.html#running-code",
    "href": "posts/01_multiple_estim_custom_stats.html#running-code",
    "title": "Multiple estimation with custom statistics",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\nhist(rnorm(1000))"
  },
  {
    "objectID": "posts/001_multiple_estim_custom_stats.html",
    "href": "posts/001_multiple_estim_custom_stats.html",
    "title": "Multiple estimation with custom statistics",
    "section": "",
    "text": "I have a dataset with two outcomes, y1 and y2, and two treatment variables, T1 and T2:\n\ndf_data <- readRDS('001_files/001_data.rds')\n\nhead(df_data)\n\n         y1        y2 T1 T2\n1 0.4811594 0.3532764  0  0\n2 0.5094737 0.3827893  0  0\n3 0.4913295 0.3866279  0  0\n4 0.4103896 0.6947368 NA  0\n5 0.3611111 0.6666667 NA  0\n6 0.4083333 0.6883117 NA  0\n\nsummary(df_data)\n\n       y1               y2                T1              T2       \n Min.   :0.1613   Min.   :0.05846   Min.   :0.000   Min.   :0.000  \n 1st Qu.:0.3875   1st Qu.:0.38557   1st Qu.:0.000   1st Qu.:0.000  \n Median :0.4348   Median :0.46651   Median :1.000   Median :1.000  \n Mean   :0.4333   Mean   :0.48190   Mean   :0.557   Mean   :0.638  \n 3rd Qu.:0.4788   3rd Qu.:0.55340   3rd Qu.:1.000   3rd Qu.:1.000  \n Max.   :0.6392   Max.   :0.93600   Max.   :1.000   Max.   :1.000  \n                                    NA's   :4288    NA's   :266    \n\n\nI want to estimate the effect of each treatment on each outcome, running 4 regressions. Additionally, I want to report the mean outcome among control units for each case. This is tricky because the estimation sample varies by treatment.\nWe’ll solve this using the packages fixest, modelsummary, and dplyr."
  },
  {
    "objectID": "posts/001_multiple_estim_custom_stats.html#running-code",
    "href": "posts/001_multiple_estim_custom_stats.html#running-code",
    "title": "Multiple estimation with custom statistics",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\ndf_dados <- readRDS('001_files/001_data.rds')\n\nhist(df_dados$y)"
  },
  {
    "objectID": "posts/001_multiple_estim_custom_stats.html#multiple-estimation-with-feols",
    "href": "posts/001_multiple_estim_custom_stats.html#multiple-estimation-with-feols",
    "title": "Multiple estimation with custom statistics",
    "section": "Multiple estimation with feols",
    "text": "Multiple estimation with feols\nThe function feols has a one-line solution to perform the four regressions I want and store it in list.\n\nlibrary(dplyr)\nlibrary(fixest)\nlibrary(modelsummary)\n\nmy_estimation <- feols(data = df_data, fml = c(y1,y2) ~ csw(T1, T2))\n\nmodelsummary(my_estimation)\n\n\n\n \n  \n      \n    lhs: y1; rhs: T1 \n     lhs: y1; rhs: T1 + T2 \n     lhs: y2; rhs: T1 \n     lhs: y2; rhs: T1 + T2 \n  \n \n\n  \n    (Intercept) \n    0.432 \n    0.426 \n    0.484 \n    0.496 \n  \n  \n     \n    (0.001) \n    (0.001) \n    (0.002) \n    (0.003) \n  \n  \n    T1 \n    0.014 \n    0.001 \n    -0.012 \n    0.020 \n  \n  \n     \n    (0.001) \n    (0.002) \n    (0.003) \n    (0.004) \n  \n  \n    T2 \n     \n    0.020 \n     \n    -0.048 \n  \n  \n     \n     \n    (0.002) \n     \n    (0.005) \n  \n  \n    Num.Obs. \n    11886 \n    11607 \n    10731 \n    10465 \n  \n  \n    R2 \n    0.013 \n    0.023 \n    0.002 \n    0.012 \n  \n  \n    R2 Adj. \n    0.013 \n    0.023 \n    0.002 \n    0.011 \n  \n  \n    AIC \n    -33004.6 \n    -32354.7 \n    -10535.3 \n    -10541.0 \n  \n  \n    BIC \n    -32989.9 \n    -32332.6 \n    -10520.7 \n    -10519.2 \n  \n  \n    RMSE \n    0.06 \n    0.06 \n    0.15 \n    0.15 \n  \n  \n    Std.Errors \n    IID \n    IID \n    IID \n    IID"
  },
  {
    "objectID": "posts/001_multiple_estim_custom_stats.html#solving-the-problem",
    "href": "posts/001_multiple_estim_custom_stats.html#solving-the-problem",
    "title": "Multiple estimation with custom statistics",
    "section": "Solving the problem",
    "text": "Solving the problem\nThe function feols has a one-line solution to perform the four regressions I want and store it in list.\n\nlibrary(dplyr)\nlibrary(fixest)\nlibrary(modelsummary)\n\nmy_estimation <- feols(data = df_data, fml = c(y1,y2) ~ sw(T1, T2))\n\nmodelsummary(my_estimation, gof_map = 'nobs')\n\n\n\n \n  \n      \n    lhs: y1; rhs: T1 \n     lhs: y1; rhs: T2 \n     lhs: y2; rhs: T1 \n     lhs: y2; rhs: T2 \n  \n \n\n  \n    (Intercept) \n    0.430 \n    0.421 \n    0.484 \n    0.501 \n  \n  \n     \n    (0.001) \n    (0.001) \n    (0.002) \n    (0.002) \n  \n  \n    T1 \n    0.015 \n     \n    -0.012 \n     \n  \n  \n     \n    (0.001) \n     \n    (0.003) \n     \n  \n  \n    T2 \n     \n    0.020 \n     \n    -0.032 \n  \n  \n     \n     \n    (0.001) \n     \n    (0.002) \n  \n  \n    Num.Obs. \n    10731 \n    14753 \n    10731 \n    14753 \n  \n\n\n\n\n\nOne obvious solution is to calculate the values by hand and adding a row in the output table using the tools of modelsummary.\nAlthough I will certainly use the tools of modelsummary I don’t want to do any manual calculation because this easily becomes a repetitive task considering many such estimations and because doing this increase the risk of typing something wrong, which would spoil the results.\nThus, I will automate the process by developing a function that takes the main data and estimation object as inputs and produce a new modelsummary object, with the appended custom statistic, as output.\n\nfn_append_mean <- function(mod_object, estimating_data){\n  \n  # Part 1: Calculate the average of the dependent variable --------------------\n  \n  # Get the variables' names\n  dep_var_name   = mod_object$fml_all$linear[[2]]\n  treatment_name = mod_object$fml_all$linear[[3]] # The index might vary depending on the formula\n  \n  # Create a vector of row indices that correspond to the subset of \n  # 'estimating_data' used in fitting the model 'mod_object'.\n  used_obs = unlist(mod_object$obs_selection)\n  \n  # Use the relevant data to calculate the average of 'dep_var_name' conditional\n  # on 'treatment_name' == 0\n  average = estimating_data[used_obs,] %>% \n    filter(!!sym(treatment_name) == 0) %>%\n    select(!!sym(dep_var_name)) %>% \n    pull() %>% \n    mean()\n  \n  # Part 2: Append the average as a statistic in the model ---------------------\n  \n  # Turn the model into a 'modelsummary_list' object\n  mod_output = modelsummary(mod_object, output = 'modelsummary_list')\n  \n  # Append the control mean\n  mod_output$glance$control.mean = average\n  \n  return(mod_output)\n  \n}\n\nLet’s check the function at work by applying it to one of the models.\n\nfn_append_mean(mod_object = my_estimation[[1]],\n               estimating_data =   df_data) \n\n$tidy\n         term   estimate    std.error statistic df.error     p.value group\n1 (Intercept) 0.42961651 0.0008821051 487.03553    10729 0.00000e+00      \n2          T1 0.01514463 0.0011817514  12.81541    10729 2.52325e-37      \n  conf.low conf.high\n1       NA        NA\n2       NA        NA\n\n$glance\n        aic       bic  r.squared adj.r.squared       rmse  nobs vcov.type\n1 -29639.18 -29624.62 0.01507677    0.01498497 0.06080203 10731       IID\n  control.mean\n1    0.4296165\n\nattr(,\"class\")\n[1] \"modelsummary_list\"\n\n\nNow, it’s a matter of applying the function to all models stored into my_estimation and adjusting the format of the statistics I want to display.\n\n# Apply the function to all models\nmy_estimation_append <- lapply(my_estimation, \n                               fn_append_mean, \n                               estimating_data = df_data)\n\n# See https://modelsummary.com/articles/modelsummary.html#fmt-round-and-format\ngm <- list(\n  list(\"raw\" = \"nobs\", \"clean\" = \"N\", \"fmt\" = \"%.0f\"),\n  list(\"raw\" = \"control.mean\", \"clean\" = \"Control mean\", \"fmt\" = \"%.3f\")\n)\n\nmodelsummary(my_estimation_append, gof_map = gm)\n\n\n\n \n  \n      \n    lhs: y1; rhs: T1 \n     lhs: y1; rhs: T2 \n     lhs: y2; rhs: T1 \n     lhs: y2; rhs: T2 \n  \n \n\n  \n    (Intercept) \n    0.430 \n    0.421 \n    0.484 \n    0.501 \n  \n  \n     \n    (0.001) \n    (0.001) \n    (0.002) \n    (0.002) \n  \n  \n    T1 \n    0.015 \n     \n    -0.012 \n     \n  \n  \n     \n    (0.001) \n     \n    (0.003) \n     \n  \n  \n    T2 \n     \n    0.020 \n     \n    -0.032 \n  \n  \n     \n     \n    (0.001) \n     \n    (0.002) \n  \n  \n    N \n    10731 \n    14753 \n    10731 \n    14753 \n  \n  \n    Control mean \n    0.430 \n    0.421 \n    0.484 \n    0.501 \n  \n\n\n\n\n\nLet’s compare with the results from a manual calculation:\n\ndf_data %>% \n  filter(T1 == 0) %>% \n  summarise_at(c('y1', 'y2'), mean)\n\n# A tibble: 1 x 2\n     y1    y2\n  <dbl> <dbl>\n1 0.430 0.484\n\ndf_data %>% \n  filter(T2 == 0) %>% \n  summarise_at(c('y1', 'y2'), mean)\n\n# A tibble: 1 x 2\n     y1    y2\n  <dbl> <dbl>\n1 0.421 0.501\n\n\nFinal Remarks The feols’s option data.save is an alternative that allows you to remove the estimating data from the function’s input list. I didn’t use that to avoid storing unnecessary data throughout the code. The calculations will be wrong if the data provided through the argument estimating_data is different from the data actually used to produce the estimation the mod_object input.\nThat’s it.\nHere’s an improved and more concise version of the text and comments:"
  },
  {
    "objectID": "posts/001_multiple_estim_custom_stats.html#the-problem",
    "href": "posts/001_multiple_estim_custom_stats.html#the-problem",
    "title": "Multiple estimation with custom statistics",
    "section": "The Problem",
    "text": "The Problem\nI have a dataset with two outcomes, y1 and y2, and two treatment variables, T1 and T2:\n\ndf_data <- readRDS('001_files/001_data.rds')\n\nhead(df_data)\n\n# A tibble: 6 x 4\n     y1    y2    T1    T2\n  <dbl> <dbl> <dbl> <dbl>\n1 0.481 0.353     0     0\n2 0.509 0.383     0     0\n3 0.491 0.387     0     0\n4 0.410 0.695    NA     0\n5 0.361 0.667    NA     0\n6 0.408 0.688    NA     0\n\nsummary(df_data)\n\n       y1               y2                T1              T2       \n Min.   :0.1613   Min.   :0.05846   Min.   :0.000   Min.   :0.000  \n 1st Qu.:0.3875   1st Qu.:0.38557   1st Qu.:0.000   1st Qu.:0.000  \n Median :0.4348   Median :0.46651   Median :1.000   Median :1.000  \n Mean   :0.4333   Mean   :0.48190   Mean   :0.557   Mean   :0.638  \n 3rd Qu.:0.4788   3rd Qu.:0.55340   3rd Qu.:1.000   3rd Qu.:1.000  \n Max.   :0.6392   Max.   :0.93600   Max.   :1.000   Max.   :1.000  \n                                    NA's   :4288    NA's   :266    \n\n\nI want to estimate the effect of each treatment on each outcome, running 4 regressions. Additionally, I want to report the mean outcome among control units for each case. This is tricky because the estimation sample varies by treatment.\nWe’ll solve this using the packages fixest, modelsummary, and dplyr."
  },
  {
    "objectID": "posts/001_multiple_estim_custom_stats.html#solution",
    "href": "posts/001_multiple_estim_custom_stats.html#solution",
    "title": "Multiple estimation with custom statistics",
    "section": "Solution",
    "text": "Solution\nThe feols function provides a one-line solution to run the four regressions and store the results in a list.\n\nlibrary(dplyr)\nlibrary(fixest)\nlibrary(modelsummary)\n\nmy_estimation <- feols(data = df_data, fml = c(y1,y2) ~ sw(T1, T2))\n\nmodelsummary(my_estimation, gof_map = 'nobs')\n\n\n\n \n  \n      \n    lhs: y1; rhs: T1 \n     lhs: y1; rhs: T2 \n     lhs: y2; rhs: T1 \n     lhs: y2; rhs: T2 \n  \n \n\n  \n    (Intercept) \n    0.430 \n    0.421 \n    0.484 \n    0.501 \n  \n  \n     \n    (0.001) \n    (0.001) \n    (0.002) \n    (0.002) \n  \n  \n    T1 \n    0.015 \n     \n    -0.012 \n     \n  \n  \n     \n    (0.001) \n     \n    (0.003) \n     \n  \n  \n    T2 \n     \n    0.020 \n     \n    -0.032 \n  \n  \n     \n     \n    (0.001) \n     \n    (0.002) \n  \n  \n    Num.Obs. \n    10731 \n    14753 \n    10731 \n    14753 \n  \n\n\n\n\n\nA manual solution would involve calculating the control means and adding a row to the output table using modelsummary tools.\nHowever, I want to automate this to avoid manual errors, especially as more models are estimated.\nThus, I’ll develop a function to append the mean control outcome to the modelsummary output.\n\nfn_append_mean <- function(mod_object, estimating_data){\n  \n  # Part 1: Calculate the mean of the dependent variable --------------------\n  \n  # Extract variable names\n  dep_var_name   = all.vars(mod_object$fml_all$linear)[1]\n  treatment_name = all.vars(mod_object$fml_all$linear)[2] # The index might vary depending on the formula\n  \n  # Get the subset of 'estimating_data' used to estimate 'mod_object'\n  used_obs = unlist(mod_object$obs_selection)\n  \n  # Calculate the mean of 'dep_var_name' where 'treatment_name' == 0\n  average = estimating_data[used_obs,] %>%\n    filter(!!sym(treatment_name) == 0) %>%\n    select(!!sym(dep_var_name)) %>%\n    pull() %>%\n    mean()\n  \n  # Part 2: Append the mean as a statistic in the model ---------------------\n  \n  # Convert the model to a 'modelsummary_list' object\n  mod_output = modelsummary(mod_object, output = 'modelsummary_list')\n  \n  # Append the control mean\n  mod_output$glance$control.mean = average\n  \n  return(mod_output)\n  \n}\n\nLet’s apply the function to one model:\n\nfn_append_mean(mod_object = my_estimation[[1]],\n               estimating_data =   df_data) \n\n$tidy\n         term   estimate    std.error statistic df.error     p.value group\n1 (Intercept) 0.42961651 0.0008821051 487.03553    10729 0.00000e+00      \n2          T1 0.01514463 0.0011817514  12.81541    10729 2.52325e-37      \n  conf.low conf.high\n1       NA        NA\n2       NA        NA\n\n$glance\n        aic       bic  r.squared adj.r.squared       rmse  nobs vcov.type\n1 -29639.18 -29624.62 0.01507677    0.01498497 0.06080203 10731       IID\n  control.mean\n1    0.4296165\n\nattr(,\"class\")\n[1] \"modelsummary_list\"\n\n\nNow, apply the function to all models and format the output statistics:\n\n# Apply the function to all models\nmy_estimation_append <- lapply(my_estimation, \n                               fn_append_mean, \n                               estimating_data = df_data)\n\n# See https://modelsummary.com/articles/modelsummary.html#fmt-round-and-format\ngm <- list(\n  list(\"raw\" = \"nobs\", \"clean\" = \"N\", \"fmt\" = \"%.0f\"),\n  list(\"raw\" = \"control.mean\", \"clean\" = \"Control mean\", \"fmt\" = \"%.3f\")\n)\n\nmodelsummary(my_estimation_append, gof_map = gm)\n\n\n\n \n  \n      \n    lhs: y1; rhs: T1 \n     lhs: y1; rhs: T2 \n     lhs: y2; rhs: T1 \n     lhs: y2; rhs: T2 \n  \n \n\n  \n    (Intercept) \n    0.430 \n    0.421 \n    0.484 \n    0.501 \n  \n  \n     \n    (0.001) \n    (0.001) \n    (0.002) \n    (0.002) \n  \n  \n    T1 \n    0.015 \n     \n    -0.012 \n     \n  \n  \n     \n    (0.001) \n     \n    (0.003) \n     \n  \n  \n    T2 \n     \n    0.020 \n     \n    -0.032 \n  \n  \n     \n     \n    (0.001) \n     \n    (0.002) \n  \n  \n    N \n    10731 \n    14753 \n    10731 \n    14753 \n  \n  \n    Control mean \n    0.430 \n    0.421 \n    0.484 \n    0.501 \n  \n\n\n\n\n\nLet’s compare with the results from a manual calculation:\n\ndf_data %>% \n  filter(T1 == 0) %>% \n  summarise_at(c('y1', 'y2'), mean)\n\n# A tibble: 1 x 2\n     y1    y2\n  <dbl> <dbl>\n1 0.430 0.484\n\ndf_data %>% \n  filter(T2 == 0) %>% \n  summarise_at(c('y1', 'y2'), mean)\n\n# A tibble: 1 x 2\n     y1    y2\n  <dbl> <dbl>\n1 0.421 0.501\n\n\nFinal Remarks\n\nThe feols option data.save could remove the need to pass estimating_data, but I chose not to store unnecessary data.\nEnsure that estimating_data matches the data used to estimate mod_object, or the results will be incorrect.\nBe cautious when using the mod_object$obs_selection object if there are missing values in the dependent variable. In such cases, the output will include both the indices of observations dropped due to NAs and those used in the estimation.\n\nThat’s it."
  }
]