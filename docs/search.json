[
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "Group size, member selection, and performance: Evidence from legislative elections in Brazil\nAccepted for publication in Economics Letters\nThis paper provides empirical evidence on the causal effects of group size on member selection and performance. Using data from local legislative elections in Brazil in a difference-in-differences framework, I explore an electoral reform that reduced the maximum number of candidates allowed in coalitions disputing legislative seats. The reform did not change the number of candidates and parties in the election, which was possible because in municipalities affected by the new cap parties reorganized into 21% more coalitions than would be expected without the reform. I discuss how the heterogeneity of the candidates combined with the coalitions’ adjustment to the reform led to the election of city councilors who were 17% wealthier, on average. Although the reform achieved the goal of reducing campaign costs, which fell by 9%, the election of wealthier politicians was an unintended consequence that weakened the representation of economically disadvantaged groups in the legislative body.\n[Manuscript]\nPeer Effects in Active Learning, with Vladimir Ponczek and Priscilla Tavares\nAugust 2024, Submitted\nThis paper studies peer effects in an active learning environment, where peer interaction is a meaningful learning mechanism. Identification of peer effects relies on the random assignment of students to different disciplines in a higher education institution. We leverage random variation in the peers’ ability distribution across groups and in the frequency at which peers meet for group work and show that social proximity among peers is increasing in the number of groups the students share and in how close they are in terms of their predetermined ability. Our main results show that replacing a socially distant peer with a closer one increases the average score of low-ability students in written exams by 2.8%. Also, the probability that low-ability students receive an evaluation corresponding to outstanding performance in group work increases by 30%, which demonstrates that social proximity makes them exert more effort. There are no detectable effects on the high-ability students’ grades. This highlights the importance of peer interaction in positive peer effects on the academic performance of low-skilled individuals.\n[Manuscript]\nDomestic Violence Law Enforcement and Women’s Labor Market Participation\nOctober, 2024\nThis paper uses Brazilian data to investigate the effects of a law aimed at tackling domestic violence on women’s labor market participation in a difference-in-differences framework. The law increased the probability of punishment of DV perpetrators, and the paper’s main hypothesis is that it improved women’s negotiating position within households, leading to a redistribution of bargaining power in favor of them. The identification strategy leverages spatial heterogeneity in the access to police stations, the first step into the justice system. The paper’s main finding shows that after the policy, married women living at an average distance of 2.7 km from a police station (the 90th percentile) would have experienced a 2.9% increase in their labor market participation rate had they lived at an average of 1.1 km (the 10th percentile). I show supporting evidence of reduced women’s hospitalization due to violence and that reporting of crimes related to domestic violence responded consistently. These findings shed light on the interplay between law enforcement, household dynamics, and labor market outcomes.\n[Manuscript]"
  },
  {
    "objectID": "research.html#working-papers",
    "href": "research.html#working-papers",
    "title": "Research",
    "section": "",
    "text": "Group size, member selection, and performance: Evidence from legislative elections in Brazil\nAccepted for publication in Economics Letters\nThis paper provides empirical evidence on the causal effects of group size on member selection and performance. Using data from local legislative elections in Brazil in a difference-in-differences framework, I explore an electoral reform that reduced the maximum number of candidates allowed in coalitions disputing legislative seats. The reform did not change the number of candidates and parties in the election, which was possible because in municipalities affected by the new cap parties reorganized into 21% more coalitions than would be expected without the reform. I discuss how the heterogeneity of the candidates combined with the coalitions’ adjustment to the reform led to the election of city councilors who were 17% wealthier, on average. Although the reform achieved the goal of reducing campaign costs, which fell by 9%, the election of wealthier politicians was an unintended consequence that weakened the representation of economically disadvantaged groups in the legislative body.\n[Manuscript]\nPeer Effects in Active Learning, with Vladimir Ponczek and Priscilla Tavares\nAugust 2024, Submitted\nThis paper studies peer effects in an active learning environment, where peer interaction is a meaningful learning mechanism. Identification of peer effects relies on the random assignment of students to different disciplines in a higher education institution. We leverage random variation in the peers’ ability distribution across groups and in the frequency at which peers meet for group work and show that social proximity among peers is increasing in the number of groups the students share and in how close they are in terms of their predetermined ability. Our main results show that replacing a socially distant peer with a closer one increases the average score of low-ability students in written exams by 2.8%. Also, the probability that low-ability students receive an evaluation corresponding to outstanding performance in group work increases by 30%, which demonstrates that social proximity makes them exert more effort. There are no detectable effects on the high-ability students’ grades. This highlights the importance of peer interaction in positive peer effects on the academic performance of low-skilled individuals.\n[Manuscript]\nDomestic Violence Law Enforcement and Women’s Labor Market Participation\nOctober, 2024\nThis paper uses Brazilian data to investigate the effects of a law aimed at tackling domestic violence on women’s labor market participation in a difference-in-differences framework. The law increased the probability of punishment of DV perpetrators, and the paper’s main hypothesis is that it improved women’s negotiating position within households, leading to a redistribution of bargaining power in favor of them. The identification strategy leverages spatial heterogeneity in the access to police stations, the first step into the justice system. The paper’s main finding shows that after the policy, married women living at an average distance of 2.7 km from a police station (the 90th percentile) would have experienced a 2.9% increase in their labor market participation rate had they lived at an average of 1.1 km (the 10th percentile). I show supporting evidence of reduced women’s hospitalization due to violence and that reporting of crimes related to domestic violence responded consistently. These findings shed light on the interplay between law enforcement, household dynamics, and labor market outcomes.\n[Manuscript]"
  },
  {
    "objectID": "research.html#work-in-progress",
    "href": "research.html#work-in-progress",
    "title": "Research",
    "section": "Work in Progress",
    "text": "Work in Progress\nTit-for-Tat between Legislative and Executive, with Eduardo Ferraz and Lucas Finamor\nCorruption Disclosure and the Dynamics of Government Coalitions\nThe Impact of Alternative Dispute Resolution Mechanisms on Violence Against Women, with Giovanna Úbida"
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "Principles of Microeconomics, Microeconomic Theory, Industrial Organization\nMathematics I and II, Linear Algebra\nProbability, Statistics, Econometrics I (cross-section)\n\n\n\n\n\nTeaching assistant in Statistics and Econometrics\n\n\n\n\n\nTeaching assitant in Microeconomic Theory, Econometrics I and III (cross-section and Panel Data)"
  },
  {
    "objectID": "teaching.html#são-paulo-school-of-economics",
    "href": "teaching.html#são-paulo-school-of-economics",
    "title": "Teaching",
    "section": "",
    "text": "Principles of Microeconomics, Microeconomic Theory, Industrial Organization\nMathematics I and II, Linear Algebra\nProbability, Statistics, Econometrics I (cross-section)\n\n\n\n\n\nTeaching assistant in Statistics and Econometrics\n\n\n\n\n\nTeaching assitant in Microeconomic Theory, Econometrics I and III (cross-section and Panel Data)"
  },
  {
    "objectID": "posts/002_multiple_estim_custom_stats_II.html",
    "href": "posts/002_multiple_estim_custom_stats_II.html",
    "title": "Multiple estimation with custom statistics II",
    "section": "",
    "text": "In this post, I tackle the same problem of the previous post, but now I use more direct approach with fixest’s etable instead of modelsummary."
  },
  {
    "objectID": "posts/002_multiple_estim_custom_stats_II.html#the-problem",
    "href": "posts/002_multiple_estim_custom_stats_II.html#the-problem",
    "title": "Multiple estimation with custom statistics II",
    "section": "The Problem",
    "text": "The Problem\nRecall the dataset: there are two outcomes, y1 and y2, and two treatment variables, T1 and T2:\n\ndf_data &lt;- readRDS('001_files/001_data.rds')\n\nhead(df_data)\n\n         y1        y2 T1 T2\n1 0.4811594 0.3532764  0  0\n2 0.5094737 0.3827893  0  0\n3 0.4913295 0.3866279  0  0\n4 0.4103896 0.6947368 NA  0\n5 0.3611111 0.6666667 NA  0\n6 0.4083333 0.6883117 NA  0\n\nsummary(df_data)\n\n       y1               y2                T1              T2       \n Min.   :0.1613   Min.   :0.05846   Min.   :0.000   Min.   :0.000  \n 1st Qu.:0.3875   1st Qu.:0.38557   1st Qu.:0.000   1st Qu.:0.000  \n Median :0.4348   Median :0.46651   Median :1.000   Median :1.000  \n Mean   :0.4333   Mean   :0.48190   Mean   :0.557   Mean   :0.638  \n 3rd Qu.:0.4788   3rd Qu.:0.55340   3rd Qu.:1.000   3rd Qu.:1.000  \n Max.   :0.6392   Max.   :0.93600   Max.   :1.000   Max.   :1.000  \n                                    NA's   :4288    NA's   :266    \n\n\nI want to estimate the effect of each treatment on each outcome, running 4 regressions.\nAdditionally, I want to report the mean outcome among control units for each case. This is tricky because the estimation sample varies by treatment.\nWe’ll solve this using the packages fixest and dplyr."
  },
  {
    "objectID": "posts/002_multiple_estim_custom_stats_II.html#solution",
    "href": "posts/002_multiple_estim_custom_stats_II.html#solution",
    "title": "Multiple estimation with custom statistics II",
    "section": "Solution",
    "text": "Solution\nUse feols to run the four regressions and store the results.\n\nlibrary(dplyr)\nlibrary(fixest)\n\nmy_estimation &lt;- feols(data = df_data, fml = c(y1,y2) ~ sw(T1, T2))\n\nThe logic behind the approach is to retrieve the model’s design matrix and then find the dependent variable values associated with the control observations. Let’s first check how it works with a single model.\n\n# The object 'my_estimation' is a list; we must retrieve some of the elements to  work with `model.matrix`\nmy_estimation_1 &lt;- my_estimation[lhs = 1, rhs = 1][[1]]\n\n# No, we get the treatment and dependent variables from the design matrix\nt &lt;- model.matrix(my_estimation_1, subset = 'T', type = 'rhs') \ny &lt;- model.matrix(my_estimation_1, type = 'lhs')\n\n# Find which rows contain the control units\ni &lt;- which(t[,1] == 0)\n\n# Compute the mean of the dependent variable for the control units\nprint(mean(y[i]))\n\n[1] 0.4296165\n\n\nRemark: I used the argument “subset” to define t, but not with y. This is because the option “rhs” produces a matrix with all regressors. By using subset = \"T\" I tell the function that I want to keep in t only columns whose names match “T”. In my case, this is sufficient to get only the treatment variable. Be cautious to ensure that you retrieve the correct variable.\nNow, I use the fitstat_register function from fixest to apply these steps to all regressions and display the computed statistic in the regression table.\nWe must supply three arguments for this function:\n\nfitstat_register(\n  type = \"meandepvar\", \n  fun = function(x) {\n    \n    t &lt;- model.matrix(x, subset = 'T', type = 'rhs') \n    y &lt;- model.matrix(x, type = 'lhs')\n    i &lt;- which(t[,1] == 0)\n    return(mean(y[i]))\n    \n    },\n  alias = \"Mean of Dep. Variable\"\n  )\n\nThe argument type establishes a name for the statistic, which you will need to refer to when calling it within the table.\nThen, we must supply the function that effectively computes the statistic using the objects available from the estimation output.\nFinally, the argument alias is the text displayed in the regression table.\nI now use etable to report the regression output, including the desired statistics with the “fitstat” argument. I include our custom “meandepvar” and the number of observations “n”.\n\netable(my_estimation,\n       fitstat = ~ meandepvar + n)\n\n                         my_estimation.1    my_estimation.2     my_estimation.3\nDependent Var.:                       y1                 y1                  y2\n                                                                               \nConstant              0.4296*** (0.0009) 0.4207*** (0.0009)  0.4839*** (0.0021)\nT1                    0.0151*** (0.0012)                    -0.0125*** (0.0029)\nT2                                       0.0197*** (0.0011)                    \n_____________________ __________________ __________________ ___________________\nS.E. type                            IID                IID                 IID\nMean of Dep. Variable            0.42962            0.42070             0.48386\nObservations                      10,731             14,753              10,731\n\n                          my_estimation.4\nDependent Var.:                        y2\n                                         \nConstant               0.5012*** (0.0020)\nT1                                       \nT2                    -0.0323*** (0.0025)\n_____________________ ___________________\nS.E. type                             IID\nMean of Dep. Variable             0.50118\nObservations                       14,753\n---\nSignif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThat’s it."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Vinicius Lima",
    "section": "",
    "text": "PhD in Economics, 2017 - 2021\nM.A. in Economics, 2015 - 2017\n\n\n\nB.A in Economics, Sept 2009 - 2013"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Vinicius Lima",
    "section": "",
    "text": "PhD in Economics, 2017 - 2021\nM.A. in Economics, 2015 - 2017\n\n\n\nB.A in Economics, Sept 2009 - 2013"
  },
  {
    "objectID": "posts/001_multiple_estim_custom_stats.html",
    "href": "posts/001_multiple_estim_custom_stats.html",
    "title": "Multiple estimation with custom statistics",
    "section": "",
    "text": "I have a dataset with two outcomes, y1 and y2, and two treatment variables, T1 and T2:\n\ndf_data &lt;- readRDS('001_files/001_data.rds')\n\nhead(df_data)\n\n         y1        y2 T1 T2\n1 0.4811594 0.3532764  0  0\n2 0.5094737 0.3827893  0  0\n3 0.4913295 0.3866279  0  0\n4 0.4103896 0.6947368 NA  0\n5 0.3611111 0.6666667 NA  0\n6 0.4083333 0.6883117 NA  0\n\nsummary(df_data)\n\n       y1               y2                T1              T2       \n Min.   :0.1613   Min.   :0.05846   Min.   :0.000   Min.   :0.000  \n 1st Qu.:0.3875   1st Qu.:0.38557   1st Qu.:0.000   1st Qu.:0.000  \n Median :0.4348   Median :0.46651   Median :1.000   Median :1.000  \n Mean   :0.4333   Mean   :0.48190   Mean   :0.557   Mean   :0.638  \n 3rd Qu.:0.4788   3rd Qu.:0.55340   3rd Qu.:1.000   3rd Qu.:1.000  \n Max.   :0.6392   Max.   :0.93600   Max.   :1.000   Max.   :1.000  \n                                    NA's   :4288    NA's   :266    \n\n\nI want to estimate the effect of each treatment on each outcome, running 4 regressions. Additionally, I want to report the mean outcome among control units for each case. This is tricky because the estimation sample varies by treatment.\nWe’ll solve this using the packages fixest, modelsummary, and dplyr."
  },
  {
    "objectID": "posts/001_multiple_estim_custom_stats.html#the-problem",
    "href": "posts/001_multiple_estim_custom_stats.html#the-problem",
    "title": "Multiple estimation with custom statistics",
    "section": "",
    "text": "I have a dataset with two outcomes, y1 and y2, and two treatment variables, T1 and T2:\n\ndf_data &lt;- readRDS('001_files/001_data.rds')\n\nhead(df_data)\n\n         y1        y2 T1 T2\n1 0.4811594 0.3532764  0  0\n2 0.5094737 0.3827893  0  0\n3 0.4913295 0.3866279  0  0\n4 0.4103896 0.6947368 NA  0\n5 0.3611111 0.6666667 NA  0\n6 0.4083333 0.6883117 NA  0\n\nsummary(df_data)\n\n       y1               y2                T1              T2       \n Min.   :0.1613   Min.   :0.05846   Min.   :0.000   Min.   :0.000  \n 1st Qu.:0.3875   1st Qu.:0.38557   1st Qu.:0.000   1st Qu.:0.000  \n Median :0.4348   Median :0.46651   Median :1.000   Median :1.000  \n Mean   :0.4333   Mean   :0.48190   Mean   :0.557   Mean   :0.638  \n 3rd Qu.:0.4788   3rd Qu.:0.55340   3rd Qu.:1.000   3rd Qu.:1.000  \n Max.   :0.6392   Max.   :0.93600   Max.   :1.000   Max.   :1.000  \n                                    NA's   :4288    NA's   :266    \n\n\nI want to estimate the effect of each treatment on each outcome, running 4 regressions. Additionally, I want to report the mean outcome among control units for each case. This is tricky because the estimation sample varies by treatment.\nWe’ll solve this using the packages fixest, modelsummary, and dplyr."
  },
  {
    "objectID": "posts/001_multiple_estim_custom_stats.html#solution",
    "href": "posts/001_multiple_estim_custom_stats.html#solution",
    "title": "Multiple estimation with custom statistics",
    "section": "Solution",
    "text": "Solution\nThe feols function provides a one-line solution to run the four regressions and store the results in a list.\n\nlibrary(dplyr)\nlibrary(fixest)\nlibrary(modelsummary)\n\nmy_estimation &lt;- feols(data = df_data, fml = c(y1,y2) ~ sw(T1, T2))\n\nmodelsummary(my_estimation, gof_map = 'nobs')\n\n\n\n\n\nlhs: y1; rhs: T1\n lhs: y1; rhs: T2\n lhs: y2; rhs: T1\n lhs: y2; rhs: T2\n\n\n\n\n(Intercept)\n0.430\n0.421\n0.484\n0.501\n\n\n\n(0.001)\n(0.001)\n(0.002)\n(0.002)\n\n\nT1\n0.015\n\n-0.012\n\n\n\n\n(0.001)\n\n(0.003)\n\n\n\nT2\n\n0.020\n\n-0.032\n\n\n\n\n(0.001)\n\n(0.002)\n\n\nNum.Obs.\n10731\n14753\n10731\n14753\n\n\n\n\n\n\n\nA manual solution would involve calculating the control means and adding a row to the output table using modelsummary tools.\nHowever, I want to automate this to avoid manual errors, especially as more models are estimated.\nThus, I’ll develop a function to append the mean control outcome to the modelsummary output.\n\nfn_append_mean &lt;- function(mod_object, estimating_data){\n  \n  # Part 1: Calculate the mean of the dependent variable --------------------\n  \n  # Extract variable names\n  dep_var_name   = all.vars(mod_object$fml_all$linear)[1]\n  treatment_name = all.vars(mod_object$fml_all$linear)[2] # The index might vary depending on the formula\n  \n  # Get the subset of 'estimating_data' used to estimate 'mod_object'\n  used_obs = unlist(mod_object$obs_selection)\n  \n  # Calculate the mean of 'dep_var_name' where 'treatment_name' == 0\n  average = estimating_data[used_obs,] %&gt;%\n    filter(!!sym(treatment_name) == 0) %&gt;%\n    select(!!sym(dep_var_name)) %&gt;%\n    pull() %&gt;%\n    mean()\n  \n  # Part 2: Append the mean as a statistic in the model ---------------------\n  \n  # Convert the model to a 'modelsummary_list' object\n  mod_output = modelsummary(mod_object, output = 'modelsummary_list')\n  \n  # Append the control mean\n  mod_output$glance$control.mean = average\n  \n  return(mod_output)\n  \n}\n\nLet’s apply the function to one model:\n\nfn_append_mean(mod_object = my_estimation[[1]],\n               estimating_data =   df_data) \n\n$tidy\n         term   estimate    std.error statistic df.error     p.value group\n1 (Intercept) 0.42961651 0.0008821051 487.03553    10729 0.00000e+00      \n2          T1 0.01514463 0.0011817514  12.81541    10729 2.52325e-37      \n  conf.low conf.high\n1       NA        NA\n2       NA        NA\n\n$glance\n        aic       bic  r.squared adj.r.squared       rmse  nobs vcov.type\n1 -29639.18 -29624.62 0.01507677    0.01498497 0.06080203 10731       IID\n  control.mean\n1    0.4296165\n\nattr(,\"class\")\n[1] \"modelsummary_list\"\n\n\nNow, apply the function to all models and format the output statistics:\n\n# Apply the function to all models\nmy_estimation_append &lt;- lapply(my_estimation, \n                               fn_append_mean, \n                               estimating_data = df_data)\n\n# See https://modelsummary.com/articles/modelsummary.html#fmt-round-and-format\ngm &lt;- list(\n  list(\"raw\" = \"nobs\", \"clean\" = \"N\", \"fmt\" = \"%.0f\"),\n  list(\"raw\" = \"control.mean\", \"clean\" = \"Control mean\", \"fmt\" = \"%.3f\")\n)\n\nmodelsummary(my_estimation_append, gof_map = gm)\n\n\n\n\n\nlhs: y1; rhs: T1\n lhs: y1; rhs: T2\n lhs: y2; rhs: T1\n lhs: y2; rhs: T2\n\n\n\n\n(Intercept)\n0.430\n0.421\n0.484\n0.501\n\n\n\n(0.001)\n(0.001)\n(0.002)\n(0.002)\n\n\nT1\n0.015\n\n-0.012\n\n\n\n\n(0.001)\n\n(0.003)\n\n\n\nT2\n\n0.020\n\n-0.032\n\n\n\n\n(0.001)\n\n(0.002)\n\n\nN\n10731\n14753\n10731\n14753\n\n\nControl mean\n0.430\n0.421\n0.484\n0.501\n\n\n\n\n\n\n\nLet’s compare with the results from a manual calculation:\n\ndf_data %&gt;% \n  filter(T1 == 0) %&gt;% \n  summarise_at(c('y1', 'y2'), mean)\n\n# A tibble: 1 x 2\n     y1    y2\n  &lt;dbl&gt; &lt;dbl&gt;\n1 0.430 0.484\n\ndf_data %&gt;% \n  filter(T2 == 0) %&gt;% \n  summarise_at(c('y1', 'y2'), mean)\n\n# A tibble: 1 x 2\n     y1    y2\n  &lt;dbl&gt; &lt;dbl&gt;\n1 0.421 0.501\n\n\nFinal Remarks\n\nThe feols option data.save could remove the need to pass estimating_data, but I chose not to store unnecessary data.\nEnsure that estimating_data matches the data used to estimate mod_object, or the results will be incorrect.\nBe cautious when using the mod_object$obs_selection object if there are missing values in the dependent variable. In such cases, the output will include both the indices of observations dropped due to NAs and those used in the estimation.\n\nThat’s it."
  },
  {
    "objectID": "rstata.html",
    "href": "rstata.html",
    "title": "Coding in R, Python and Stata",
    "section": "",
    "text": "It’s likely that you won’t find any brand new content here compared to what you can find making some research on the web.\nHowever, I built this page to serve as a kind of personal library gathering a lot of stuff I did in both R and Stata.\nThe content is organized into the categories that see in the right bar.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultiple estimation with custom statistics\n\n\n\n\n\n\n\n\n\n\n\nVinicius Lima\n\n\n\n\n\n\n\n\n\n\n\n\nMultiple estimation with custom statistics II\n\n\n\n\n\n\n\n\n\n\n\nVinicius Lima\n\n\n\n\n\n\nNo matching items"
  }
]